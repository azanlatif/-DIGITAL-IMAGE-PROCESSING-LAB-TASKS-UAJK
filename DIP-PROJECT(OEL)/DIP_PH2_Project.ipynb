{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39c709ca"
      },
      "source": [
        "# Digital Image Processing - Project Overview\n",
        "## Submitted By: AZAN LATIF\n",
        "## ROll NO: 2023-SE-14\n",
        "\n",
        "\n",
        ">This project focuses on developing an automated system for melanoma detection from dermoscopic images. The process is broken down into several key stages:\n",
        "\n",
        "### 1. Lesion Segmentation & Mask Generation\n",
        "This initial phase involves pre-processing dermoscopic images to isolate the lesion area. It includes:\n",
        "*   **Image Enhancement**: Improving image quality through techniques like CLAHE to adjust contrast.\n",
        "*   **Hair Removal**: Eliminating hair artifacts using morphological operations (e.g., black-hat transform) and inpainting to ensure cleaner lesion boundaries.\n",
        "*   **Lesion Segmentation**: Applying techniques like Otsu's thresholding, morphological closing, and flood fill to accurately delineate the lesion from the surrounding skin, generating a binary mask for each lesion.\n",
        "\n",
        "### 2. Feature Extraction\n",
        "Once the lesions are segmented, relevant features are extracted from the masked areas of the original images. These features are typically quantitative measurements that describe the lesion's characteristics, such as color (mean and standard deviation for BGR channels) and potentially texture or shape descriptors.\n",
        "\n",
        "### 3. Classification\n",
        "Extracted features are then used to train a machine learning classifier (e.g., Random Forest). The classifier learns patterns from these features to distinguish between benign lesions and melanoma.\n",
        "\n",
        "### 4. Evaluation\n",
        "Both the segmentation and classification steps are rigorously evaluated using appropriate metrics:\n",
        "*   **Segmentation Evaluation**: Assessing the accuracy of generated masks against ground truth masks (e.g., using confusion matrix metrics like Accuracy, Sensitivity, and Specificity).\n",
        "*   **Classification Evaluation**: Measuring the performance of the trained classifier (e.g., Accuracy, Precision, Recall, F1-score) on a held-out test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4688a60"
      },
      "source": [
        "It seems the issue is due to a data imbalance, where your dataset `y` (and consequently `y_train` and `y_test`) contains only one class. This causes the classification metrics to be 1.0 because the model is only predicting that single class, which is always correct within the given test set. Let's verify the class distribution:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "210c2330",
        "outputId": "307a1882-970e-4042-ef39-18e04036bcf1"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(\"Value counts for all labels (y):\\n\", pd.Series(y).value_counts())\n",
        "print(\"\\nValue counts for training labels (y_train):\\n\", pd.Series(y_train).value_counts())\n",
        "print(\"\\nValue counts for test labels (y_test):\\n\", pd.Series(y_test).value_counts())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for all labels (y):\n",
            " 0    167\n",
            "1     33\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for training labels (y_train):\n",
            " 0    134\n",
            "1     26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for test labels (y_test):\n",
            " 0    33\n",
            "1     7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c199dfb1-dc1b-4010-821e-2d9fa1b31710",
        "id": "ShgvmapvX8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset\""
      ],
      "metadata": {
        "id": "e6gfZVSWX8b7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(BASE_PATH)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290ccc99-a787-4620-b9d3-48936400273f",
        "id": "DVE3De5JX8b8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PH2_dataset.xlsx', 'PH2_dataset.txt', 'Readme.txt', 'PH2 Dataset images', 'generated_masks']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PROJECT START\n",
        "\n",
        "Task 1 â€” Lesion Segmentation & Mask Generation\n",
        "\n",
        "ðŸ”¹ Required Libraries"
      ],
      "metadata": {
        "id": "SM4lLQIGX8b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "jimjAhu7X8b-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Helper Functions (Image Processing Pipeline) 1ï¸âƒ£ Image Enhancement"
      ],
      "metadata": {
        "id": "2UqZHk14X8b-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enhance_image(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "    l = clahe.apply(l)\n",
        "    enhanced = cv2.merge((l, a, b))\n",
        "    return cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)"
      ],
      "metadata": {
        "id": "M2ruUivpX8cA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2ï¸âƒ£ Hair Removal (Black-hat + Inpainting)"
      ],
      "metadata": {
        "id": "FoT5FtBFX8cB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_hairs(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17,17))\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "    _, mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "    return cv2.inpaint(img, mask, 1, cv2.INPAINT_TELEA)"
      ],
      "metadata": {
        "id": "49Enzep1X8cC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3ï¸âƒ£ Lesion Segmentation"
      ],
      "metadata": {
        "id": "-pdH9xXpX8cC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_lesion(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blur = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "\n",
        "    _, binary = cv2.threshold(\n",
        "    blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n",
        ")\n",
        "\n",
        "\n",
        "    # 1ï¸âƒ£ CLOSE â€” lesion boundaries connect karne ke liye\n",
        "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (7,7))\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_close)\n",
        "\n",
        "    # 2ï¸âƒ£ FILL HOLES â€” gaps remove karne ke liye\n",
        "    h, w = binary.shape\n",
        "    floodfill = binary.copy()\n",
        "    mask = np.zeros((h+2, w+2), np.uint8)\n",
        "    cv2.floodFill(floodfill, mask, (0,0), 255)\n",
        "    floodfill_inv = cv2.bitwise_not(floodfill)\n",
        "    filled = binary | floodfill_inv\n",
        "\n",
        "    return filled"
      ],
      "metadata": {
        "id": "r-VLQZ0UX8cD"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ”¹ Main Mask Generation Loop"
      ],
      "metadata": {
        "id": "Tea40YFUX8cE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/generated_masks\"\n",
        "\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "os.makedirs(SAVE_PATH, exist_ok=True)\n",
        "\n",
        "y_true_all, y_pred_all = [], []\n",
        "\n",
        "for folder in tqdm(os.listdir(BASE_PATH)):\n",
        "    folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(\n",
        "        folder_path, f\"{folder}_Dermoscopic_Image\"\n",
        "    )\n",
        "    gt_path = os.path.join(\n",
        "        folder_path, f\"{folder}_lesion\"\n",
        "    )\n",
        "\n",
        "    img_file = os.listdir(img_path)[0]\n",
        "    gt_file  = os.listdir(gt_path)[0]\n",
        "\n",
        "    img = cv2.imread(os.path.join(img_path, img_file))\n",
        "    gt  = cv2.imread(os.path.join(gt_path, gt_file), 0)\n",
        "\n",
        "    if img is None or gt is None:\n",
        "        continue\n",
        "\n",
        "    img = enhance_image(img)\n",
        "    img = remove_hairs(img)\n",
        "    pred_mask = segment_lesion(img)\n",
        "\n",
        "    cv2.imwrite(\n",
        "        os.path.join(SAVE_PATH, f\"{folder}_mask.png\"),\n",
        "        pred_mask\n",
        "    )\n",
        "\n",
        "    y_true_all.extend((gt > 0).flatten())\n",
        "    y_pred_all.extend((pred_mask > 0).flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed515c13-867c-4d83-9b3f-9e8274ea446c",
        "id": "V6_PNN0sX8cE"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [01:08<00:00,  2.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7acfb2f1",
        "outputId": "5db549c4-fd71-4e23-874f-8679a2b9fa31"
      },
      "source": [
        "import os\n",
        "\n",
        "path_to_verify = '/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images'\n",
        "\n",
        "if os.path.exists(path_to_verify):\n",
        "    if os.path.isdir(path_to_verify):\n",
        "        print(f\"Path '{path_to_verify}' exists and is a directory.\")\n",
        "        print(\"Contents (first 10 items):\", os.listdir(path_to_verify)[:5])\n",
        "    else:\n",
        "        print(f\"Path '{path_to_verify}' exists but is not a directory.\")\n",
        "else:\n",
        "    print(f\"Path '{path_to_verify}' does not exist.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path '/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images' exists and is a directory.\n",
            "Contents (first 10 items): ['IMD002', 'IMD003', 'IMD004', 'IMD008', 'IMD006']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ“Š 3. Segmentation Evaluation (Dataset-Level)"
      ],
      "metadata": {
        "id": "03uObx-xX8cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true_all, y_pred_all)\n",
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "sensitivity = TP / (TP + FN)\n",
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(f\"Accuracy     : {accuracy:.4f}\")\n",
        "print(f\"Sensitivity  : {sensitivity:.4f}\")\n",
        "print(f\"Specificity  : {specificity:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d3f72c-e680-4fe8-a4e0-0b2a1b23188c",
        "id": "4wQNHu2uX8cF"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[ 2133754 57593928]\n",
            " [  933741 27501900]]\n",
            "Accuracy     : 0.3361\n",
            "Sensitivity  : 0.9672\n",
            "Specificity  : 0.0357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import libraries and mount drive"
      ],
      "metadata": {
        "id": "eJhApqOBX_LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "BASE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/Masks\"  # jahan masks saved hain\n",
        "LABEL_TXT = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2_dataset.txt\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVqoBHlfYBSH",
        "outputId": "e9df562e-6604-4426-872c-311fb94edd93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load labels from .txt file"
      ],
      "metadata": {
        "id": "z0zMgsixYE0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {}\n",
        "\n",
        "with open(LABEL_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    parts = line.strip().split(\"||\")\n",
        "    parts = [p.strip() for p in parts if p.strip() != \"\"]\n",
        "\n",
        "    # Skip header\n",
        "    if parts[0] == \"Name\":\n",
        "        continue\n",
        "\n",
        "    img_id = parts[0]\n",
        "\n",
        "    try:\n",
        "        melanoma_val = parts[-1].split()[0]\n",
        "        melanoma_val = int(melanoma_val)\n",
        "        label = 1 if melanoma_val > 0 else 0\n",
        "        label_dict[img_id] = label\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Total labels loaded:\", len(label_dict))\n",
        "print(\"Sample:\", list(label_dict.items())[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icGyUArRYHB3",
        "outputId": "680e65d6-6479-47db-f58e-162c6f544f78"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labels loaded: 212\n",
            "Sample: [('IMD003', 1), ('IMD009', 1), ('IMD016', 1), ('IMD022', 1), ('IMD024', 1), ('IMD025', 1), ('IMD035', 1), ('IMD038', 1), ('IMD042', 1), ('IMD044', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define feature extraction function"
      ],
      "metadata": {
        "id": "1_hGQL_eYRvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(img, mask):\n",
        "    features = []\n",
        "\n",
        "    # strict binary mask\n",
        "    mask = (mask > 0).astype(np.uint8)\n",
        "\n",
        "    for i in range(3):  # BGR channels\n",
        "        channel = img[:, :, i]\n",
        "        lesion_pixels = channel[mask == 1]\n",
        "\n",
        "        if lesion_pixels.size < 50:   # too small region\n",
        "            features.extend([0, 0])\n",
        "        else:\n",
        "            features.extend([\n",
        "                np.mean(lesion_pixels) / 255.0,\n",
        "                np.std(lesion_pixels) / 255.0\n",
        "            ])\n",
        "    return features\n",
        "\n"
      ],
      "metadata": {
        "id": "lcgm4j6eYUL1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load images, masks, extract features"
      ],
      "metadata": {
        "id": "Xe7WxQ7nYW_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------\n",
        "# Step 0: Mount Drive\n",
        "# ----------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----------------------\n",
        "# Step 1: Define Paths\n",
        "# ----------------------\n",
        "BASE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/generated_masks\"\n",
        "LABEL_TXT = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2_dataset.txt\"\n",
        "\n",
        "# ----------------------\n",
        "# Step 2: Load Labels from .txt\n",
        "# ----------------------\n",
        "label_dict = {}\n",
        "\n",
        "with open(LABEL_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    parts = line.strip().split(\"||\")\n",
        "    parts = [p.strip() for p in parts if p.strip() != \"\"]\n",
        "\n",
        "    # Skip header\n",
        "    if parts[0] == \"Name\":\n",
        "        continue\n",
        "\n",
        "    img_id = parts[0]\n",
        "\n",
        "    try:\n",
        "        melanoma_val = parts[-1].split()[0]\n",
        "        melanoma_val = int(melanoma_val)\n",
        "        label = 1 if melanoma_val > 0 else 0\n",
        "        label_dict[img_id] = label\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(\"Total labels loaded:\", len(label_dict))\n",
        "print(\"Sample labels:\", list(label_dict.items())[:10])\n",
        "\n",
        "# ----------------------\n",
        "# Step 3: Define Feature Extraction\n",
        "# ----------------------\n",
        "def extract_features(img, mask):\n",
        "    \"\"\"\n",
        "    Extract simple features from masked image:\n",
        "    mean and std for each channel (BGR)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Ensure mask is binary\n",
        "    _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    for i in range(3):  # B, G, R channels\n",
        "        masked_pixels = img[:, :, i][mask_bin > 0]\n",
        "        if masked_pixels.size == 0:\n",
        "            features.extend([0, 0])\n",
        "        else:\n",
        "            features.extend([masked_pixels.mean(), masked_pixels.std()])\n",
        "    return features  # total 6 features\n",
        "\n",
        "# ----------------------\n",
        "# Step 4: Load Images, Masks and Extract Features\n",
        "# ----------------------\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "missing_masks = []\n",
        "missing_images = []\n",
        "\n",
        "for folder in os.listdir(BASE_PATH):\n",
        "    folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "    if folder not in label_dict:\n",
        "        continue\n",
        "\n",
        "    # Mask path\n",
        "    mask_path = os.path.join(SAVE_PATH, f\"{folder}_mask.png\")\n",
        "    if not os.path.exists(mask_path):\n",
        "        missing_masks.append(folder)\n",
        "        continue\n",
        "\n",
        "    # Image path\n",
        "    img_folder = os.path.join(folder_path, f\"{folder}_Dermoscopic_Image\")\n",
        "    if not os.path.exists(img_folder):\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_files = os.listdir(img_folder)\n",
        "    if len(img_files) == 0:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_file = img_files[0]\n",
        "    img = cv2.imread(os.path.join(img_folder, img_file))\n",
        "    mask = cv2.imread(mask_path, 0)  # grayscale\n",
        "\n",
        "    if img is None or mask is None:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    feats = extract_features(img, mask)\n",
        "    X.append(feats)\n",
        "    y.append(label_dict[folder])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Missing masks:\", len(missing_masks))\n",
        "print(\"Missing images:\", len(missing_images))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM3_QiNhYYbp",
        "outputId": "959b9d91-6d1c-44f8-a4cf-3d451baa535f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total labels loaded: 212\n",
            "Sample labels: [('IMD003', 1), ('IMD009', 1), ('IMD016', 1), ('IMD022', 1), ('IMD024', 1), ('IMD025', 1), ('IMD035', 1), ('IMD038', 1), ('IMD042', 1), ('IMD044', 1)]\n",
            "Features shape: (200, 6)\n",
            "Labels shape: (200,)\n",
            "Missing masks: 0\n",
            "Missing images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train/Test Split Example"
      ],
      "metadata": {
        "id": "1hxFGsJ5a2oE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")"
      ],
      "metadata": {
        "id": "Eu03wPL5a4tb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier:"
      ],
      "metadata": {
        "id": "I_X0fqlgbYyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Random Forest\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=5,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAOt72zoa8yG",
        "outputId": "7aeebf2d-6831-48aa-93a2-18b1fff888cc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        40\n",
            "\n",
            "    accuracy                           1.00        40\n",
            "   macro avg       1.00      1.00      1.00        40\n",
            "weighted avg       1.00      1.00      1.00        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70fdb47e"
      },
      "source": [
        "# Task\n",
        "Update the label extraction logic in cell `cM3_QiNhYYbp` to correctly parse the 'Clinical Diagnosis' column from `PH2_dataset.txt`, mapping '2' to '1' (Melanoma) and all other values to '0' (Benign). Then, run the modified cell to reload features and labels. Subsequently, re-run the train-test split, print the value counts for `y`, `y_train`, and `y_test` to confirm the new label distribution, and finally, re-train and re-evaluate the Random Forest classifier to assess its performance with the corrected labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a32ef0a0"
      },
      "source": [
        "## Correct Label Extraction\n",
        "\n",
        "### Subtask:\n",
        "Modify the existing code in cell `cM3_QiNhYYbp` to correctly extract labels from the `PH2_dataset.txt` file, mapping '2' from the 'Clinical Diagnosis' column to '1' (Melanoma) and all other values to '0' (Benign).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f031a9e5"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to modify the label extraction logic in cell `cM3_QiNhYYbp` to correctly map 'Clinical Diagnosis' values to binary labels. I will provide the updated code for that cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5025442d",
        "outputId": "ef654d3a-9e51-4421-bb35-f7686149ad2a"
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------\n",
        "# Step 0: Mount Drive\n",
        "# ----------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ----------------------\n",
        "# Step 1: Define Paths\n",
        "# ----------------------\n",
        "BASE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2 Dataset images\"\n",
        "SAVE_PATH = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/generated_masks\"\n",
        "LABEL_TXT = \"/content/drive/MyDrive/PH_2_PROJECT/PH2Dataset/PH2_dataset.txt\"\n",
        "\n",
        "# ----------------------\n",
        "# Step 2: Load Labels from .txt\n",
        "# ----------------------\n",
        "label_dict = {}\n",
        "\n",
        "with open(LABEL_TXT, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for line in lines:\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    parts = line.strip().split(\"||\")\n",
        "    parts = [p.strip() for p in parts if p.strip() != \"\"]\n",
        "\n",
        "    # Skip header\n",
        "    if parts[0] == \"Name\":\n",
        "        continue\n",
        "\n",
        "    img_id = parts[0]\n",
        "\n",
        "    try:\n",
        "        clinical_diagnosis_str = parts[2].strip() # Extract 'Clinical Diagnosis' column\n",
        "        label = 1 if clinical_diagnosis_str == '2' else 0 # Map '2' to 1 (Melanoma), others to 0 (Benign)\n",
        "        label_dict[img_id] = label\n",
        "    except IndexError:\n",
        "        print(f\"Warning: Clinical Diagnosis column not found for {img_id}, skipping.\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Error processing clinical diagnosis for {img_id}: {e}, skipping.\")\n",
        "        continue\n",
        "\n",
        "print(\"Total labels loaded:\", len(label_dict))\n",
        "print(\"Sample labels:\", list(label_dict.items())[:10])\n",
        "\n",
        "# ----------------------\n",
        "# Step 3: Define Feature Extraction\n",
        "# ----------------------\n",
        "def extract_features(img, mask):\n",
        "    \"\"\"\n",
        "    Extract simple features from masked image:\n",
        "    mean and std for each channel (BGR)\n",
        "    \"\"\"\n",
        "    features = []\n",
        "\n",
        "    # Ensure mask is binary\n",
        "    _, mask_bin = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    for i in range(3):  # B, G, R channels\n",
        "        masked_pixels = img[:, :, i][mask_bin > 0]\n",
        "        if masked_pixels.size == 0:\n",
        "            features.extend([0, 0])\n",
        "        else:\n",
        "            features.extend([masked_pixels.mean(), masked_pixels.std()])\n",
        "    return features  # total 6 features\n",
        "\n",
        "# ----------------------\n",
        "# Step 4: Load Images, Masks and Extract Features\n",
        "# ----------------------\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "missing_masks = []\n",
        "missing_images = []\n",
        "\n",
        "for folder in os.listdir(BASE_PATH):\n",
        "    folder_path = os.path.join(BASE_PATH, folder)\n",
        "\n",
        "    if folder not in label_dict:\n",
        "        continue\n",
        "\n",
        "    # Mask path\n",
        "    mask_path = os.path.join(SAVE_PATH, f\"{folder}_mask.png\")\n",
        "    if not os.path.exists(mask_path):\n",
        "        missing_masks.append(folder)\n",
        "        continue\n",
        "\n",
        "    # Image path\n",
        "    img_folder = os.path.join(folder_path, f\"{folder}_Dermoscopic_Image\")\n",
        "    if not os.path.exists(img_folder):\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_files = os.listdir(img_folder)\n",
        "    if len(img_files) == 0:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    img_file = img_files[0]\n",
        "    img = cv2.imread(os.path.join(img_folder, img_file))\n",
        "    mask = cv2.imread(mask_path, 0)  # grayscale\n",
        "\n",
        "    if img is None or mask is None:\n",
        "        missing_images.append(folder)\n",
        "        continue\n",
        "\n",
        "    feats = extract_features(img, mask)\n",
        "    X.append(feats)\n",
        "    y.append(label_dict[folder])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n",
        "print(\"Missing masks:\", len(missing_masks))\n",
        "print(\"Missing images:\", len(missing_images))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Warning: Clinical Diagnosis column not found for Legends for Clinical Diagnosis:, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 0 - Common Nevus;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 1 - Atypical Nevus;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 2 - Melanoma., skipping.\n",
            "Warning: Clinical Diagnosis column not found for Legends for Asymmetry:, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 0 - Fully Symmetric;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 1 - Symetric in 1 axe;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 2 - Fully Asymmetric;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for Legends for Pigment Network, Dots/Globules, Streaks, Regression Areas, and Blue-Whitish Veil:, skipping.\n",
            "Warning: Clinical Diagnosis column not found for A  - Absent;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for AT - Atypical;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for P  - Present;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for T  - Typical., skipping.\n",
            "Warning: Clinical Diagnosis column not found for Legends for Colors:, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 1 - White;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 2 - Red;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 3 - Light-Brown;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 4 - Dark-Brown;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 5 - Blue-Gray;, skipping.\n",
            "Warning: Clinical Diagnosis column not found for 6 - Black., skipping.\n",
            "Total labels loaded: 200\n",
            "Sample labels: [('IMD003', 0), ('IMD009', 0), ('IMD016', 0), ('IMD022', 0), ('IMD024', 0), ('IMD025', 0), ('IMD035', 0), ('IMD038', 0), ('IMD042', 0), ('IMD044', 0)]\n",
            "Features shape: (200, 6)\n",
            "Labels shape: (200,)\n",
            "Missing masks: 0\n",
            "Missing images: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9823d04"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the labels `y` have been reloaded with the correct logic, I need to re-run the train-test split to ensure `y_train` and `y_test` reflect the new label distribution. Then, I will print the value counts for `y`, `y_train`, and `y_test` to confirm the class distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52bba48f",
        "outputId": "9342a59b-6cef-4496-d6b1-63a01fe98ae9"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd # Import pandas for value_counts\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(\"Value counts for all labels (y):\\n\", pd.Series(y).value_counts())\n",
        "print(\"\\nValue counts for training labels (y_train):\\n\", pd.Series(y_train).value_counts())\n",
        "print(\"\\nValue counts for test labels (y_test):\\n\", pd.Series(y_test).value_counts())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for all labels (y):\n",
            " 0    167\n",
            "1     33\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for training labels (y_train):\n",
            " 0    134\n",
            "1     26\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Value counts for test labels (y_test):\n",
            " 0    33\n",
            "1     7\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e39b2482"
      },
      "source": [
        "**Reasoning**:\n",
        "The labels have been corrected and the data split. The next logical step is to re-train the Random Forest classifier with the updated `X_train` and `y_train` and then evaluate its performance on the `X_test` and `y_test` to reflect the new label distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f5d2a0f",
        "outputId": "824f919c-6914-432d-9711-12ba808d2cc9"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train Random Forest\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=5,\n",
        "    min_samples_split=5,\n",
        "    random_state=42\n",
        ")\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.85\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      1.00      0.92        33\n",
            "           1       1.00      0.14      0.25         7\n",
            "\n",
            "    accuracy                           0.85        40\n",
            "   macro avg       0.92      0.57      0.58        40\n",
            "weighted avg       0.87      0.85      0.80        40\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55b3f4ca"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the changes made, the new label distribution, and the resulting performance metrics of the classifier. If significant class imbalance still exists and affects performance, I will suggest further steps.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45bbc13e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Summarize the changes made:**\n",
        "    The label extraction logic in cell `cM3_QiNhYYbp` was updated to correctly parse the 'Clinical Diagnosis' column from `PH2_dataset.txt`. Specifically, values of '2' were mapped to '1' (Melanoma), and all other values were mapped to '0' (Benign). Following this, features and labels were reloaded, the train-test split was re-executed with stratification, and the Random Forest classifier was re-trained and re-evaluated.\n",
        "2.  **Summarize the new label distribution:**\n",
        "    The total dataset consists of 200 samples. The new label distribution is 167 instances for label '0' (Benign) and 33 instances for label '1' (Melanoma). The train-test split preserved this distribution proportionally: the training set has 134 instances of '0' and 26 of '1', while the test set has 33 instances of '0' and 7 of '1'.\n",
        "3.  **Summarize the resulting performance metrics of the classifier:**\n",
        "    The Random Forest classifier achieved an overall accuracy of 0.85 on the test set. For the minority class ('1', Melanoma), the precision was 1.00, but the recall was very low at 0.14. This means that while all instances predicted as Melanoma were correct, the model missed a significant number of actual Melanoma cases. For the majority class ('0', Benign), the precision was 0.85, and the recall was 1.00.\n",
        "4.  **Does significant class imbalance still exist and affect performance?**\n",
        "    Yes, significant class imbalance still exists (167 Benign vs. 33 Melanoma in the full dataset, 33 Benign vs. 7 Melanoma in the test set). This imbalance severely affects the model's performance for the minority class (Melanoma), as evidenced by its very low recall of 0.14, indicating the model struggles to identify positive cases.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Label extraction was successfully updated to map 'Clinical Diagnosis' '2' to Melanoma (1) and other values to Benign (0).\n",
        "*   The dataset exhibits a significant class imbalance, with 167 instances labeled as Benign ($83.5\\%$) and 33 instances labeled as Melanoma ($16.5\\%$) out of 200 total samples.\n",
        "*   The train-test split maintained this imbalance, with the test set containing 33 Benign and 7 Melanoma samples.\n",
        "*   The Random Forest classifier achieved an overall accuracy of $85\\%$.\n",
        "*   Performance for the minority class (Melanoma) is very poor in terms of recall ($0.14$), meaning only $14\\%$ of actual Melanoma cases were correctly identified by the model.\n",
        "*   The precision for Melanoma is $1.00$, indicating that all cases predicted as Melanoma were indeed Melanoma.\n",
        "*   Performance for the majority class (Benign) is strong, with a recall of $1.00$ and precision of $0.85$.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   Address the significant class imbalance using techniques such as oversampling (e.g., SMOTE), undersampling, or adjusting class weights within the classifier to improve the recall for the minority class (Melanoma).\n",
        "*   Re-evaluate model performance using metrics more robust to class imbalance, such as the F1-score or Area Under the Receiver Operating Characteristic (AU-ROC) curve, to get a more comprehensive understanding of the model's effectiveness, especially for the critical minority class.\n"
      ]
    }
  ]
}